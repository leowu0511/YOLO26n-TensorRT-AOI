#include "YoloDetector.h"
#include <opencv2/cudawarping.hpp>  // GPU ç¸®æ”¾
#include <opencv2/cudaarithm.hpp>   // GPU çŸ©é™£é‹ç®—
#include <opencv2/cudaimgproc.hpp>  // GPU è‰²å½©è½‰æ›

YoloDetector::YoloDetector(const std::string& enginePath) : mEnginePath(enginePath) {}

YoloDetector::~YoloDetector() {
    if (mInputBuffer) cudaFree(mInputBuffer);
    if (mOutputBuffer) cudaFree(mOutputBuffer);
    if (mStream) cudaStreamDestroy(mStream);

    if (mContext) delete mContext;
    if (mEngine) delete mEngine;
    if (mRuntime) delete mRuntime;
}

bool YoloDetector::init() {
    std::ifstream file(mEnginePath, std::ios::binary);
    if (!file.good()) {
        std::cerr << "éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°å¼•æ“æª”æ¡ˆ " << mEnginePath << std::endl;
        return false;
    }

    file.seekg(0, file.end);
    size_t size = file.tellg();
    file.seekg(0, file.beg);
    std::vector<char> engineData(size);
    file.read(engineData.data(), size);
    file.close();

    mRuntime = nvinfer1::createInferRuntime(mLogger);
    if (!mRuntime) return false;

    mEngine = mRuntime->deserializeCudaEngine(engineData.data(), size);
    if (!mEngine) return false;

    mContext = mEngine->createExecutionContext();
    if (!mContext) return false;

    if (cudaStreamCreate(&mStream) != cudaSuccess) {
        std::cerr << "CUDA Stream å»ºç«‹å¤±æ•—" << std::endl;
        return false;
    }

    const char* inputName = mEngine->getIOTensorName(0);
    const char* outputName = mEngine->getIOTensorName(1);

    // ğŸ’¡ é€™è£¡æ˜¯å›ºå®šè¼¸å…¥è¼¸å‡ºå¤§å° (èˆ‡ YOLO26n çµæ§‹å°æ‡‰)
    mInputSize = 1 * 3 * 640 * 640 * sizeof(float);
    mOutputSize = 1 * 6 * 8400 * sizeof(float);

    if (cudaMalloc(&mInputBuffer, mInputSize) != cudaSuccess) return false;
    if (cudaMalloc(&mOutputBuffer, mOutputSize) != cudaSuccess) return false;

    mContext->setTensorAddress(inputName, mInputBuffer);
    mContext->setTensorAddress(outputName, mOutputBuffer);

    std::cout << ">>> YoloDetector åˆå§‹åŒ–æˆåŠŸ [RTX 4060 ç¡¬é«”åŠ é€Ÿå•Ÿå‹•]" << std::endl;
    return true;
}

std::vector<Detection> YoloDetector::detect(const cv::Mat& img) {
    if (img.empty()) return {};

    // 1. [æ¥µé€Ÿå„ªåŒ–] å…¨ GPU é è™•ç† (å–ä»£åŸæœ¬çš„ CPU è¿´åœˆ)
    preprocessGPU(img);

    // 2. åŸ·è¡ŒéåŒæ­¥æ¨è«–
    mContext->enqueueV3(mStream);

    // 3. å–å›è³‡æ–™ (Host è¨˜æ†¶é«”åˆ†é…ä¸€æ¬¡å³å¯å„ªåŒ–ï¼Œé€™è£¡å…ˆç¶­æŒç°¡å–®ç‰ˆ)
    std::vector<float> outputData(mOutputSize / sizeof(float));
    cudaMemcpyAsync(outputData.data(), mOutputBuffer, mOutputSize, cudaMemcpyDeviceToHost, mStream);
    cudaStreamSynchronize(mStream);

    // 4. å¾Œè™•ç† (é€™éƒ¨åˆ†é€šå¸¸åœ¨ CPU è·‘)
    return postprocess(outputData, img.size());
}

/**
 * ğŸ’¡ GPU é è™•ç†å‡½å¼ï¼šå°‡æ‰€æœ‰è¨ˆç®—é–æ­»åœ¨ RTX 4060 å…§
 */
void YoloDetector::preprocessGPU(const cv::Mat& img) {
    cv::cuda::GpuMat d_img, d_resized, d_rgb, d_float;

    // 1. ä¸Šå‚³åœ–ç‰‡åˆ° GPU
    d_img.upload(img, cv::cuda::Stream::Null());

    // 2. GPU ç¸®æ”¾ (ä¿æŒé•·å¯¬æ¯”çš„é‚è¼¯å¯æ•´åˆæˆ–ç°¡åŒ–)
    cv::cuda::resize(d_img, d_resized, cv::Size(mInputW, mInputH), 0, 0, cv::INTER_LINEAR, cv::cuda::Stream::Null());

    // 3. è‰²å½©è½‰æ› BGR -> RGB ä¸¦è½‰ç‚ºæµ®é»æ•¸
    cv::cuda::cvtColor(d_resized, d_rgb, cv::COLOR_BGR2RGB, 3, cv::cuda::Stream::Null());

    // 4. æ­£è¦åŒ– (0-255 -> 0.0-1.0)
    d_rgb.convertTo(d_float, CV_32FC3, 1.0 / 255.0, cv::cuda::Stream::Null());

    // ğŸ’¡ 5. ç¶­åº¦è½‰æ› (HWC -> CHW)ï¼šé€™æ˜¯æé€Ÿé—œéµ
    // å°‡äº¤éŒ¯çš„ RGB åƒç´ åˆ†æ‹†æˆä¸‰å€‹ç¨ç«‹å¹³é¢ï¼Œç›´æ¥å¯«å…¥ TensorRT çš„ Input Buffer
    std::vector<cv::cuda::GpuMat> chw_channels(3);
    for (int i = 0; i < 3; ++i) {
        chw_channels[i] = cv::cuda::GpuMat(mInputH, mInputW, CV_32FC1, (float*)mInputBuffer + i * mInputW * mInputH);
    }
    cv::cuda::split(d_float, chw_channels, cv::cuda::Stream::Null());
}

std::vector<Detection> YoloDetector::postprocess(const std::vector<float>& output, const cv::Size& originalSize) {
    std::vector<Detection> detections;
    const float* data = output.data();
    int numAnchors = 8400; // YOLOv8/YOLO26 æ¨™æº–è¼¸å‡ºæ•¸é‡
    int stride = 6;        // x, y, w, h, confidence, classId

    float scale = std::min((float)mInputW / originalSize.width, (float)mInputH / originalSize.height);
    float xOffset = (mInputW - (originalSize.width * scale)) / 2;
    float yOffset = (mInputH - (originalSize.height * scale)) / 2;

    std::vector<int> classIds;
    std::vector<float> confidences;
    std::vector<cv::Rect> boxes;

    for (int i = 0; i < numAnchors; ++i) {
        const float* row = data + (i * stride);
        float confidence = row[4];

        if (confidence > 0.25f) {
            int classId = (int)row[5];

            // ğŸ’¡ é€™è£¡å°‡åº§æ¨™é‚„åŸå›åŸå§‹åœ–ç‰‡å°ºå¯¸
            float cx = row[0];
            float cy = row[1];
            float w = row[2];
            float h = row[3];

            int left = (int)((cx - w / 2 - xOffset) / scale);
            int top = (int)((cy - h / 2 - yOffset) / scale);
            int width = (int)(w / scale);
            int height = (int)(h / scale);

            classIds.push_back(classId);
            confidences.push_back(confidence);
            boxes.push_back(cv::Rect(left, top, width, height));
        }
    }

    std::vector<int> indices;
    cv::dnn::NMSBoxes(boxes, confidences, 0.25f, 0.45f, indices);

    for (int idx : indices) {
        Detection det;
        det.classId = classIds[idx];
        det.confidence = confidences[idx];
        det.box = boxes[idx];
        detections.push_back(det);
    }
    return detections;
}
